"""
–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞ —Å GPT-5 Pro (Responses API) –ø–æ id –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ—Ç–≤–µ—Ç–∞

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ (Windows CMD, –∏–∑ –ø–∞–ø–∫–∏ Browser_Use):
  1) –ü–æ JSON —Ñ–∞–π–ª—É –æ—Ç–≤–µ—Ç–∞:
     ..\.venv\Scripts\python.exe continue_gpt5_pro_chat.py --json "gpt5_self_learning_solution_20251019_021017.json" --question "–ö–æ—Ä–æ—Ç–∫–æ —Ä–µ–∑—é–º–∏—Ä—É–π –∏ –¥–∞–π —á–µ–∫–ª–∏—Å—Ç –≤–Ω–µ–¥—Ä–µ–Ω–∏—è"

  2) –ù–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –ø–æ id –æ—Ç–≤–µ—Ç–∞:
     ..\.venv\Scripts\python.exe continue_gpt5_pro_chat.py --response-id "resp_01a6b1b8055245090068f41c4ca19081908c1dc2f34757b2b5" --question "–ß—Ç–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤ safe_screenshot?"

–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
  --json <path>           –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É JSON –æ—Ç–≤–µ—Ç—É (–∫–∞–∫ –≤ gpt5_self_learning_solution_*.json)
  --response-id <id>      –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ—Ç–≤–µ—Ç–∞ (resp_...)
  --question <text>       Follow-up –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Çe–ª—è
  --model <name>          –ú–æ–¥–µ–ª—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ—Ä–µ—Ç—Å—è –∏–∑ JSON, –∏–Ω–∞—á–µ gpt-5-pro)
  --max-output-tokens N   –õ–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –æ—Ç–≤–µ—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY
"""

from __future__ import annotations
import os
import json
import argparse
from pathlib import Path
from datetime import datetime
import time
import requests
from typing import Optional
import random

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
RESPONSES_URL = "https://api.openai.com/v1/responses"


def load_response_json(json_path: Path) -> dict:
    with open(json_path, "r", encoding="utf-8") as f:
        return json.load(f)


def extract_model_from_json(data: dict) -> Optional[str]:
    # –ü—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å —Ç–æ—á–Ω–æ–µ –∏–º—è –º–æ–¥–µ–ª–∏ –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
    # –ü—Ä–∏–º–µ—Ä—ã: "gpt-5-pro" –∏–ª–∏ "gpt-5-pro-2025-10-06"
    return data.get("model") or (data.get("response", {}) if False else None)


def extract_response_id(data: dict) -> Optional[str]:
    # –ò—â–µ–º id –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–µ—Ä—Ö–Ω–µ–º —É—Ä–æ–≤–Ω–µ
    # –ü—Ä–∏–º–µ—Ä: "id": "resp_..."
    return data.get("id")


def build_headers() -> dict:
    if not OPENAI_API_KEY:
        raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω OPENAI_API_KEY –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
    return {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json",
    }


def build_payload(question: str, model: str, previous_response_id: str, max_output_tokens: Optional[int] = None) -> dict:
    payload = {
        "model": model,
        "input": [
            {"role": "user", "content": question}
        ],
        "previous_response_id": previous_response_id,
        # –•—Ä–∞–Ω–∏–º —Ç—Ä–µ–¥, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –≤ –±—É–¥—É—â–µ–º
        "store": True,
    }
    if max_output_tokens:
        # –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ API –ø—Ä–∏–Ω–∏–º–∞—é—Ç max_output_tokens –ª–∏–±–æ max_output_tokens/max_completion_tokens
        payload["max_output_tokens"] = int(max_output_tokens)
    return payload


def send_followup(
    question: str,
    response_id: str,
    model: Optional[str],
    max_output_tokens: Optional[int],
    pre_wait: float = 0.0,
    attempts: int = 5,
    base_backoff: float = 8.0,
    max_backoff: float = 120.0,
):
    model_final = model or "gpt-5-pro"
    headers = build_headers()
    payload = build_payload(question=question, model=model_final, previous_response_id=response_id, max_output_tokens=max_output_tokens)

    print("\nüì§ –û—Ç–ø—Ä–∞–≤–∫–∞ follow-up –≤ —Ç–æ—Ç –∂–µ —á–∞—Ç GPT-5 Pro...")
    print(f"   previous_response_id: {response_id}")
    print(f"   model: {model_final}")

    # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ (—Å–º—è–≥—á–∏—Ç—å –≤—Å–ø–ª–µ—Å–∫–∏)
    if pre_wait and pre_wait > 0:
        print(f"   ‚è≥ –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º: {int(pre_wait)} —Å–µ–∫...")
        time.sleep(pre_wait)

    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–æ–≤—Ç–æ—Ä–æ–≤ –Ω–∞ 429/5xx —Å –¥–∂–∏—Ç—Ç–µ—Ä–æ–º –∏ —É–≤–∞–∂–µ–Ω–∏–µ–º Retry-After
    last_error_text = None
    for i in range(1, attempts + 1):
        try:
            r = requests.post(RESPONSES_URL, headers=headers, json=payload)
        except requests.RequestException as e:
            last_error_text = str(e)
            if i < attempts:
                # –ù–µ–±–æ–ª—å—à–æ–π –¥–∂–∏—Ç—Ç–µ—Ä –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º —Å–µ—Ç–∏
                sleep_s = min(base_backoff * (2 ** (i - 1)), max_backoff) + random.uniform(0, 1.5)
                print(f"‚ö†Ô∏è  –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞: {e}. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {int(sleep_s)} —Å–µ–∫ (–ø–æ–ø—ã—Ç–∫–∞ {i}/{attempts})...")
                time.sleep(sleep_s)
                continue
            raise RuntimeError(f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ API –ø–æ—Å–ª–µ {attempts} –ø–æ–ø—ã—Ç–æ–∫: {last_error_text}")

        if r.status_code == 200:
            break
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ 429/5xx
        if r.status_code in (429, 500, 502, 503, 504) and i < attempts:
            retry_after = r.headers.get("retry-after")
            if retry_after:
                try:
                    wait_s = float(retry_after)
                except ValueError:
                    wait_s = None
            else:
                wait_s = None

            if wait_s is None:
                # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –±—ç–∫–æ—Ñ—Ñ —Å –¥–∂–∏—Ç—Ç–µ—Ä–æ–º
                wait_s = min(base_backoff * (2 ** (i - 1)), max_backoff) + random.uniform(0, 2.0)

            brief_text = r.text[:200].replace("\n", " ") if r.text else ""
            print(f"‚ö†Ô∏è  {r.status_code} –æ—Ç API. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {int(wait_s)} —Å–µ–∫ (–ø–æ–ø—ã—Ç–∫–∞ {i}/{attempts})... –î–µ—Ç–∞–ª–∏: {brief_text}")
            time.sleep(wait_s)
            continue

        # –ò–Ω—ã–µ –æ—à–∏–±–∫–∏ ‚Äî —Å—Ä–∞–∑—É –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º
        raise RuntimeError(f"–û—à–∏–±–∫–∞ API: {r.status_code} - {r.text}")

    data = r.json()
    return data


def extract_output_text(data: dict) -> str:
    # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
    # –í–∞—Ä–∏–∞–Ω—Ç 1: –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–æ–±–∞–≤–ª—è—é—Ç 'output_text'
    if isinstance(data.get("output_text"), str):
        return data["output_text"].strip()

    # –í–∞—Ä–∏–∞–Ω—Ç 2: –æ–±–æ–π—Ç–∏ –º–∞—Å—Å–∏–≤ 'output' –∏ –¥–æ—Å—Ç–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏ –∏–∑ message.content
    out = data.get("output")
    texts: list[str] = []
    if isinstance(out, list):
        for item in out:
            if not isinstance(item, dict):
                continue
            if item.get("type") == "message":
                # –í –Ω–æ–≤—ã—Ö –æ—Ç–≤–µ—Ç–∞—Ö message.content ‚Äî –º–∞—Å—Å–∏–≤ –±–ª–æ–∫–æ–≤
                for block in item.get("content", []) or []:
                    # –ò—â–µ–º –±–ª–æ–∫–∏ —Ç–∏–ø–∞ output_text/text
                    if isinstance(block, dict):
                        if block.get("type") in ("output_text", "text"):
                            t = block.get("text")
                            if isinstance(t, str):
                                texts.append(t)
    if texts:
        return "\n\n".join(texts).strip()

    # –§–æ–ª–ª–±—ç–∫: raw JSON
    return json.dumps(data, ensure_ascii=False, indent=2)


def save_followup(data: dict, base_dir: Path) -> Path:
    base_dir.mkdir(parents=True, exist_ok=True)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    json_path = base_dir / f"gpt5_followup_{ts}.json"
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏–º –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    txt = extract_output_text(data)
    txt_path = base_dir / f"gpt5_followup_{ts}.txt"
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write(txt)
    print(f"\nüíæ Follow-up —Å–æ—Ö—Ä–∞–Ω–µ–Ω:\n   JSON: {json_path}\n   TEXT: {txt_path}")
    return json_path


def main():
    parser = argparse.ArgumentParser(description="–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –¥–∏–∞–ª–æ–≥ —Å GPT-5 Pro —á–µ—Ä–µ–∑ previous_response_id (Responses API)")
    parser.add_argument("--json", dest="json_path", help="–ü—É—Ç—å –∫ —Ä–∞–Ω–µ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É JSON –æ—Ç–≤–µ—Ç—É (gpt5_self_learning_solution_*.json)")
    parser.add_argument("--response-id", dest="response_id", help="ID –æ—Ç–≤–µ—Ç–∞ (resp_...)")
    parser.add_argument("--question", required=False, help="Follow-up –≤–æ–ø—Ä–æ—Å –¥–ª—è GPT-5 Pro")
    parser.add_argument("--question-file", dest="question_file", required=False, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Ç–µ–∫—Å—Ç–æ–º –≤–æ–ø—Ä–æ—Å–∞ (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ --question)")
    parser.add_argument("--model", dest="model", help="–ò–º—è –º–æ–¥–µ–ª–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ JSON –∏–ª–∏ gpt-5-pro)")
    parser.add_argument("--max-output-tokens", dest="max_output_tokens", type=int, default=None, help="–õ–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –æ—Ç–≤–µ—Ç–∞")
    parser.add_argument("--out", dest="out_dir", default="logs", help="–ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è follow-up (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é logs)")
    parser.add_argument("--pre-wait", dest="pre_wait", type=float, default=0.0, help="–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–µ—Ä–≤—ã–º –∑–∞–ø—Ä–æ—Å–æ–º (—Å–µ–∫)")
    parser.add_argument("--retries", dest="retries", type=int, default=5, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ 429/5xx")

    args = parser.parse_args()

    if not OPENAI_API_KEY:
        raise SystemExit("‚ùå OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ.")

    response_id: Optional[str] = args.response_id
    model: Optional[str] = args.model
    question: Optional[str] = args.question

    # –†–∞–∑—Ä–µ—à–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –≤–æ–ø—Ä–æ—Å–∞ –∏–∑ —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω --question-file
    if args.question_file:
        qpath = Path(args.question_file)
        if not qpath.exists():
            raise SystemExit(f"–§–∞–π–ª –≤–æ–ø—Ä–æ—Å–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {qpath}")
        question = qpath.read_text(encoding="utf-8", errors="ignore")

    if not question or not question.strip():
        raise SystemExit("–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å --question –∏–ª–∏ --question-file —Å –Ω–µ–ø—É—Å—Ç—ã–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º")

    original_max_output_tokens: Optional[int] = None

    if not response_id:
        if not args.json_path:
            raise SystemExit("–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å --json <file> –∏–ª–∏ --response-id <id>")
        # –ì—Ä—É–∑–∏–º JSON –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º id + –º–æ–¥–µ–ª—å
        json_file = Path(args.json_path)
        if not json_file.exists():
            raise SystemExit(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {json_file}")
        data = load_response_json(json_file)
        response_id = extract_response_id(data)
        if not response_id:
            raise SystemExit("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å id –∏–∑ JSON (–æ–∂–∏–¥–∞–ª–∏ –ø–æ–ª–µ 'id')")
        if not model:
            model = extract_model_from_json(data) or "gpt-5-pro"
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ –∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤, –µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –∏—Å—Ö–æ–¥–Ω–æ–º JSON
        try:
            original_max_output_tokens = data.get("max_output_tokens")
            if isinstance(original_max_output_tokens, str):
                original_max_output_tokens = int(original_max_output_tokens)
            if not isinstance(original_max_output_tokens, int):
                original_max_output_tokens = None
        except Exception:
            original_max_output_tokens = None
    else:
        if not model:
            model = "gpt-5-pro"

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º follow-up
    # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –∑–∞–¥–∞–ª –ª–∏–º–∏—Ç, –Ω–æ –æ–Ω –±—ã–ª –≤ –∏—Å—Ö–æ–¥–Ω–æ–º JSON ‚Äî –ø—Ä–∏–º–µ–Ω–∏–º –µ–≥–æ; –∏–Ω–∞—á–µ –Ω–µ –ø–µ—Ä–µ–¥–∞—ë–º –≤–æ–≤—Å–µ
    effective_max_tokens = args.max_output_tokens if args.max_output_tokens is not None else original_max_output_tokens
    data = send_followup(
        question=question,
        response_id=response_id,
        model=model,
        max_output_tokens=effective_max_tokens,
        pre_wait=float(args.pre_wait or 0.0),
        attempts=int(args.retries or 5),
    )

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    out_dir = Path(args.out_dir)
    save_followup(data, out_dir)

    # –ü–µ—á–∞—Ç–∞–µ–º –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –≤ –∫–æ–Ω—Å–æ–ª—å
    print("\nüì• –û—Ç–≤–µ—Ç GPT-5 Pro (–∫—Ä–∞—Ç–∫–æ):\n" + "-" * 80)
    print(extract_output_text(data)[:4000])
    print("\n" + "-" * 80)


if __name__ == "__main__":
    main()
